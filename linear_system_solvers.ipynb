{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d79278",
   "metadata": {},
   "source": [
    "# Solving Linear Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d49d3ee",
   "metadata": {},
   "source": [
    "## LU decomposition\n",
    "\n",
    "LU decomposition is a matrix factorization technique that decomposes a square matrix $A$ into the product of a lower triangular matrix $L$ and an upper triangular matrix $U$, such that $A = L \\cdot U$.\n",
    "\n",
    "This decomposition is particularly useful for solving systems of linear equations $A \\mathbf{x} = \\mathbf{b}$, as it allows us to break down the problem into two simpler triangular systems:\n",
    "\n",
    "1. Solve $L \\mathbf{y} = \\mathbf{b}$ for $\\mathbf{y}$\n",
    "2. Solve $U \\mathbf{x} = \\mathbf{y}$ for $\\mathbf{x}$\n",
    "\n",
    "In this notebook, we'll demonstrate how to perform LU decomposition and use it to solve linear systems using Python's NumPy library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0106d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7e7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lu_decomposition(A):\n",
    "    \"\"\"\n",
    "    Perform LU decomposition of matrix A.\n",
    "    Returns L and U such that A = L @ U\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    L = np.eye(n)\n",
    "    U = A.copy().astype(float)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if U[i, i] == 0:\n",
    "                raise ValueError(\"LU decomposition failed: zero pivot\")\n",
    "            factor = U[j, i] / U[i, i]\n",
    "            L[j, i] = factor\n",
    "            U[j, :] -= factor * U[i, :]\n",
    "    \n",
    "    return L, U\n",
    "\n",
    "def forward_substitution(L, b):\n",
    "    \"\"\"\n",
    "    Solve L y = b for y\n",
    "    \"\"\"\n",
    "    n = L.shape[0]\n",
    "    y = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        y[i] = b[i]\n",
    "        for j in range(i):\n",
    "            y[i] -= L[i, j] * y[j]\n",
    "        y[i] /= L[i, i]\n",
    "    return y\n",
    "\n",
    "def backward_substitution(U, y):\n",
    "    \"\"\"\n",
    "    Solve U x = y for x\n",
    "    \"\"\"\n",
    "    n = U.shape[0]\n",
    "    x = np.zeros(n)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        x[i] = y[i]\n",
    "        for j in range(i+1, n):\n",
    "            x[i] -= U[i, j] * x[j]\n",
    "        x[i] /= U[i, i]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221b34c",
   "metadata": {},
   "source": [
    "## What is LU Decomposition?\n",
    "\n",
    "LU decomposition factors a matrix $A$ into:\n",
    "\n",
    "$$A = L \\cdot U$$\n",
    "\n",
    "Where:\n",
    "- $L$ is a lower triangular matrix with 1s on the diagonal\n",
    "- $U$ is an upper triangular matrix\n",
    "\n",
    "For a system $A \\mathbf{x} = \\mathbf{b}$, we can write:\n",
    "\n",
    "$$L \\cdot U \\cdot \\mathbf{x} = \\mathbf{b}$$\n",
    "\n",
    "Let $\\mathbf{y} = U \\cdot \\mathbf{x}$, then:\n",
    "\n",
    "$$L \\cdot \\mathbf{y} = \\mathbf{b}$$\n",
    "\n",
    "Solving for $\\mathbf{y}$ is easy since $L$ is lower triangular, then solve $U \\cdot \\mathbf{x} = \\mathbf{y}$ for $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "790cbf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[4. 3. 2.]\n",
      " [1. 2. 1.]\n",
      " [2. 1. 3.]]\n",
      "\n",
      "Vector b:\n",
      "[10.  5.  8.]\n"
     ]
    }
   ],
   "source": [
    "# Example matrix A and vector b\n",
    "A = np.array([[4, 3, 2],\n",
    "              [1, 2, 1],\n",
    "              [2, 1, 3]], dtype=float)\n",
    "\n",
    "b = np.array([10, 5, 8], dtype=float)\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print(\"\\nVector b:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0efa2b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower triangular matrix L:\n",
      "[[ 1.    0.    0.  ]\n",
      " [ 0.25  1.    0.  ]\n",
      " [ 0.5  -0.4   1.  ]]\n",
      "\n",
      "Upper triangular matrix U:\n",
      "[[4.   3.   2.  ]\n",
      " [0.   1.25 0.5 ]\n",
      " [0.   0.   2.2 ]]\n",
      "\n",
      "Verify A = L @ U:\n",
      "[[4. 3. 2.]\n",
      " [1. 2. 1.]\n",
      " [2. 1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# Perform LU decomposition\n",
    "L, U = lu_decomposition(A)\n",
    "\n",
    "print(\"Lower triangular matrix L:\")\n",
    "print(L)\n",
    "print(\"\\nUpper triangular matrix U:\")\n",
    "print(U)\n",
    "print(\"\\nVerify A = L @ U:\")\n",
    "print(L @ U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486b4e81",
   "metadata": {},
   "source": [
    "## Solving the Linear System\n",
    "\n",
    "To solve $A \\mathbf{x} = \\mathbf{b}$ using LU decomposition:\n",
    "\n",
    "1. First, solve $L \\mathbf{y} = \\mathbf{b}$ for $\\mathbf{y}$ (forward substitution)\n",
    "2. Then, solve $U \\mathbf{x} = \\mathbf{y}$ for $\\mathbf{x}$ (backward substitution)\n",
    "\n",
    "Note: In some implementations, pivoting is used for numerical stability, but this assumes no pivoting is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2102a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate vector y:\n",
      "[10.   2.5  4. ]\n",
      "\n",
      "Solution vector x:\n",
      "[0.63636364 1.27272727 1.81818182]\n",
      "\n",
      "Verification A @ x:\n",
      "[10.  5.  8.]\n",
      "Original b:\n",
      "[10.  5.  8.]\n"
     ]
    }
   ],
   "source": [
    "# Solve the system using LU decomposition\n",
    "# First, solve L y = b\n",
    "y = forward_substitution(L, b)\n",
    "print(\"Intermediate vector y:\")\n",
    "print(y)\n",
    "\n",
    "# Then, solve U x = y\n",
    "x = backward_substitution(U, y)\n",
    "print(\"\\nSolution vector x:\")\n",
    "print(x)\n",
    "\n",
    "# Verify the solution\n",
    "print(\"\\nVerification A @ x:\")\n",
    "print(A @ x)\n",
    "print(\"Original b:\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524de14b",
   "metadata": {},
   "source": [
    "## Cholesky Factorization\n",
    "\n",
    "Cholesky factorization is a special case of LU decomposition that applies to symmetric positive definite matrices. It decomposes a matrix $A$ into the product of a lower triangular matrix $L$ and its transpose $L^T$, such that:\n",
    "\n",
    "$$A = L \\cdot L^T$$\n",
    "\n",
    "Where:\n",
    "- $L$ is a lower triangular matrix with positive diagonal elements\n",
    "- $A$ must be symmetric ($A = A^T$) and positive definite (all eigenvalues positive)\n",
    "\n",
    "This factorization is more efficient than general LU decomposition and is numerically stable. It's commonly used in applications like least squares problems, Kalman filtering, and Monte Carlo simulations.\n",
    "\n",
    "For solving $A \\mathbf{x} = \\mathbf{b}$, we can write:\n",
    "\n",
    "$$L \\cdot L^T \\cdot \\mathbf{x} = \\mathbf{b}$$\n",
    "\n",
    "Let $\\mathbf{y} = L^T \\cdot \\mathbf{x}$, then:\n",
    "\n",
    "$$L \\cdot \\mathbf{y} = \\mathbf{b}$$\n",
    "\n",
    "Solving for $\\mathbf{y}$ using forward substitution, then solve $L^T \\cdot \\mathbf{x} = \\mathbf{y}$ using backward substitution (since $L^T$ is upper triangular)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d821f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric positive definite matrix A:\n",
      "[[4. 2. 1.]\n",
      " [2. 5. 3.]\n",
      " [1. 3. 6.]]\n",
      "\n",
      "Vector b:\n",
      "[ 7. 12. 15.]\n",
      "\n",
      "Lower triangular matrix L:\n",
      "[[2.         0.         0.        ]\n",
      " [1.         2.         0.        ]\n",
      " [0.5        1.25       2.04633819]]\n",
      "\n",
      "Verify A = L @ L.T:\n",
      "[[4. 2. 1.]\n",
      " [2. 5. 3.]\n",
      " [1. 3. 6.]]\n"
     ]
    }
   ],
   "source": [
    "def cholesky_decomposition(A):\n",
    "    \"\"\"\n",
    "    Perform Cholesky decomposition of a symmetric positive definite matrix A.\n",
    "    Returns L such that A = L @ L.T\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    L = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            L[i, j] = (A[i, j] - np.sum(L[i, :j] * L[j, :j])) / L[j, j]\n",
    "        L[i, i] = np.sqrt(A[i, i] - np.sum(L[i, :i] ** 2))\n",
    "    \n",
    "    return L\n",
    "\n",
    "# Example: Symmetric positive definite matrix\n",
    "A_chol = np.array([[4, 2, 1],\n",
    "                    [2, 5, 3],\n",
    "                    [1, 3, 6]], dtype=float)\n",
    "\n",
    "b_chol = np.array([7, 12, 15], dtype=float)\n",
    "\n",
    "print(\"Symmetric positive definite matrix A:\")\n",
    "print(A_chol)\n",
    "print(\"\\nVector b:\")\n",
    "print(b_chol)\n",
    "\n",
    "# Perform Cholesky decomposition\n",
    "L = cholesky_decomposition(A_chol)\n",
    "\n",
    "print(\"\\nLower triangular matrix L:\")\n",
    "print(L)\n",
    "print(\"\\nVerify A = L @ L.T:\")\n",
    "print(L @ L.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4da3246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate vector y:\n",
      "[3.5        4.25       3.87887986]\n",
      "\n",
      "Solution vector x:\n",
      "[0.80597015 0.94029851 1.89552239]\n",
      "\n",
      "Verification A @ x:\n",
      "[ 7. 12. 15.]\n",
      "Original b:\n",
      "[ 7. 12. 15.]\n"
     ]
    }
   ],
   "source": [
    "# Solve the system using Cholesky decomposition\n",
    "# First, solve L y = b\n",
    "y_chol = forward_substitution(L, b_chol)\n",
    "print(\"Intermediate vector y:\")\n",
    "print(y_chol)\n",
    "\n",
    "# Then, solve L.T x = y (backward substitution since L.T is upper triangular)\n",
    "x_chol = backward_substitution(L.T, y_chol)\n",
    "print(\"\\nSolution vector x:\")\n",
    "print(x_chol)\n",
    "\n",
    "# Verify the solution\n",
    "print(\"\\nVerification A @ x:\")\n",
    "print(A_chol @ x_chol)\n",
    "print(\"Original b:\")\n",
    "print(b_chol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325504e5",
   "metadata": {},
   "source": [
    "## Iterative Methods for Solving Linear Systems\n",
    "\n",
    "While direct methods like LU decomposition and Cholesky factorization provide exact solutions in a finite number of steps, iterative methods approximate the solution through successive refinements. These methods are particularly useful for large sparse matrices where direct methods become computationally expensive.\n",
    "\n",
    "### Jacobi Method\n",
    "\n",
    "The Jacobi method is the simplest iterative technique. It updates all components of the solution vector simultaneously using the values from the previous iteration:\n",
    "\n",
    "$$x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j \\neq i} a_{ij} x_j^{(k)} \\right)$$\n",
    "\n",
    "Convergence is guaranteed if the matrix is strictly diagonally dominant or symmetric positive definite.\n",
    "\n",
    "### Gauss-Seidel Method\n",
    "\n",
    "The Gauss-Seidel method improves upon Jacobi by using the most recently computed values within the same iteration:\n",
    "\n",
    "$$x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \\right)$$\n",
    "\n",
    "This method generally converges faster than Jacobi for the same matrices.\n",
    "\n",
    "### Successive Over-Relaxation (SOR) Method\n",
    "\n",
    "SOR introduces a relaxation factor ω to accelerate convergence:\n",
    "\n",
    "$$x_i^{(k+1)} = (1 - \\omega) x_i^{(k)} + \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \\right)$$\n",
    "\n",
    "- For ω = 1, SOR reduces to Gauss-Seidel\n",
    "- For 0 < ω < 1, it's under-relaxation (slower convergence)\n",
    "- For 1 < ω < 2, it's over-relaxation (potentially faster convergence)\n",
    "\n",
    "The optimal ω depends on the matrix properties and is typically found experimentally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "329f199f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_method(A, b, x0=None, tol=1e-10, max_iter=100):\n",
    "    \"\"\"\n",
    "    Solve A x = b using Jacobi iterative method.\n",
    "    Returns solution x and number of iterations.\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    if x0 is None:\n",
    "        x0 = np.zeros(n)\n",
    "    x = x0.copy()\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        x_new = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            x_new[i] = (b[i] - np.sum(A[i, :] * x) + A[i, i] * x[i]) / A[i, i]\n",
    "        \n",
    "        if np.linalg.norm(x_new - x) < tol:\n",
    "            return x_new, k + 1\n",
    "        x = x_new\n",
    "    \n",
    "    return x, max_iter\n",
    "\n",
    "def gauss_seidel_method(A, b, x0=None, tol=1e-10, max_iter=100):\n",
    "    \"\"\"\n",
    "    Solve A x = b using Gauss-Seidel iterative method.\n",
    "    Returns solution x and number of iterations.\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    if x0 is None:\n",
    "        x0 = np.zeros(n)\n",
    "    x = x0.copy()\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        x_old = x.copy()\n",
    "        for i in range(n):\n",
    "            x[i] = (b[i] - np.sum(A[i, :i] * x[:i]) - np.sum(A[i, i+1:] * x_old[i+1:])) / A[i, i]\n",
    "        \n",
    "        if np.linalg.norm(x - x_old) < tol:\n",
    "            return x, k + 1\n",
    "    \n",
    "    return x, max_iter\n",
    "\n",
    "def sor_method(A, b, omega=1.25, x0=None, tol=1e-10, max_iter=100):\n",
    "    \"\"\"\n",
    "    Solve A x = b using Successive Over-Relaxation (SOR) method.\n",
    "    Returns solution x and number of iterations.\n",
    "    \"\"\"\n",
    "    n = A.shape[0]\n",
    "    if x0 is None:\n",
    "        x0 = np.zeros(n)\n",
    "    x = x0.copy()\n",
    "    \n",
    "    for k in range(max_iter):\n",
    "        x_old = x.copy()\n",
    "        for i in range(n):\n",
    "            sigma = np.sum(A[i, :i] * x[:i]) + np.sum(A[i, i+1:] * x_old[i+1:])\n",
    "            x[i] = (1 - omega) * x_old[i] + (omega / A[i, i]) * (b[i] - sigma)\n",
    "        \n",
    "        if np.linalg.norm(x - x_old) < tol:\n",
    "            return x, k + 1\n",
    "    \n",
    "    return x, max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fec5ee60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A (diagonally dominant):\n",
      "[[10.  2.  1.]\n",
      " [ 1.  8.  2.]\n",
      " [ 2.  1.  9.]]\n",
      "\n",
      "Vector b:\n",
      "[13. 11. 12.]\n",
      "\n",
      "Jacobi method converged in 23 iterations\n",
      "Solution: [1. 1. 1.]\n",
      "Verification A @ x: [13. 11. 12.]\n",
      "\n",
      "Gauss-Seidel method converged in 12 iterations\n",
      "Solution: [1. 1. 1.]\n",
      "Verification A @ x: [13. 11. 12.]\n",
      "\n",
      "SOR method (ω=1.25) converged in 23 iterations\n",
      "Solution: [1. 1. 1.]\n",
      "Verification A @ x: [13. 11. 12.]\n"
     ]
    }
   ],
   "source": [
    "# Example: Diagonally dominant matrix for iterative methods\n",
    "A_iter = np.array([[10, 2, 1],\n",
    "                   [1, 8, 2],\n",
    "                   [2, 1, 9]], dtype=float)\n",
    "\n",
    "b_iter = np.array([13, 11, 12], dtype=float)\n",
    "\n",
    "print(\"Matrix A (diagonally dominant):\")\n",
    "print(A_iter)\n",
    "print(\"\\nVector b:\")\n",
    "print(b_iter)\n",
    "\n",
    "# Initial guess\n",
    "x0 = np.zeros(3)\n",
    "\n",
    "# Jacobi method\n",
    "x_jacobi, iter_jacobi = jacobi_method(A_iter, b_iter, x0)\n",
    "print(f\"\\nJacobi method converged in {iter_jacobi} iterations\")\n",
    "print(\"Solution:\", x_jacobi)\n",
    "print(\"Verification A @ x:\", A_iter @ x_jacobi)\n",
    "\n",
    "# Gauss-Seidel method\n",
    "x_gs, iter_gs = gauss_seidel_method(A_iter, b_iter, x0)\n",
    "print(f\"\\nGauss-Seidel method converged in {iter_gs} iterations\")\n",
    "print(\"Solution:\", x_gs)\n",
    "print(\"Verification A @ x:\", A_iter @ x_gs)\n",
    "\n",
    "# SOR method with omega = 1.25\n",
    "x_sor, iter_sor = sor_method(A_iter, b_iter, omega=1.25, x0=x0)\n",
    "print(f\"\\nSOR method (ω=1.25) converged in {iter_sor} iterations\")\n",
    "print(\"Solution:\", x_sor)\n",
    "print(\"Verification A @ x:\", A_iter @ x_sor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0a63e2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has covered both direct and iterative methods for solving linear systems:\n",
    "\n",
    "**Direct Methods:**\n",
    "- LU decomposition: Works for general square matrices, decomposes in $O(n^3)$ time\n",
    "- Cholesky factorization: Specialized for symmetric positive definite matrices, more efficient than LU\n",
    "\n",
    "**Iterative Methods:**\n",
    "- Jacobi method: Simple simultaneous updates, converges for diagonally dominant matrices\n",
    "- Gauss-Seidel method: Uses latest values within iteration, generally faster than Jacobi\n",
    "- SOR method: Relaxation-based acceleration, optimal ω can significantly improve convergence\n",
    "\n",
    "Direct methods provide exact solutions in finite steps but require $O(n^3)$ operations. Iterative methods approximate solutions through successive refinements and are preferred for large sparse systems where direct methods become impractical.\n",
    "\n",
    "The choice of method depends on matrix properties (sparsity, structure, conditioning) and problem size. Understanding these fundamental algorithms helps in selecting appropriate numerical methods and appreciating the optimizations in libraries like NumPy and SciPy.\n",
    "\n",
    "Experiment with different matrices, relaxation factors, and convergence tolerances to see how these methods perform!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a64cf4",
   "metadata": {},
   "source": [
    "## Glossary\n",
    "\n",
    "- **LU Decomposition**: A matrix factorization technique that decomposes a square matrix $A$ into the product of a lower triangular matrix $L$ and an upper triangular matrix $U$ ($A = L \\cdot U$).\n",
    "\n",
    "- **Lower Triangular Matrix**: A square matrix where all entries above the main diagonal are zero.\n",
    "\n",
    "- **Upper Triangular Matrix**: A square matrix where all entries below the main diagonal are zero.\n",
    "\n",
    "- **Cholesky Factorization**: A special LU decomposition for symmetric positive definite matrices, where $U = L^T$ ($A = L \\cdot L^T$).\n",
    "\n",
    "- **Symmetric Matrix**: A square matrix that equals its transpose ($A = A^T$).\n",
    "\n",
    "- **Positive Definite Matrix**: A symmetric matrix where all eigenvalues are positive, ensuring $x^T A x > 0$ for all non-zero vectors $x$.\n",
    "\n",
    "- **Diagonal Dominance**: A property where the absolute value of each diagonal element is greater than or equal to the sum of absolute values of other elements in its row/column, guaranteeing convergence of iterative methods.\n",
    "\n",
    "- **Jacobi Method**: An iterative technique that updates all components of the solution vector simultaneously using the values from the previous iteration: $x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j \\neq i} a_{ij} x_j^{(k)} \\right)$.\n",
    "\n",
    "- **Gauss-Seidel Method**: An iterative method that uses the most recently computed values within the same iteration: $x_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \\right)$.\n",
    "\n",
    "- **Successive Over-Relaxation (SOR)**: An accelerated iterative method that combines Gauss-Seidel with a relaxation factor $\\omega$: $x_i^{(k+1)} = (1 - \\omega) x_i^{(k)} + \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \\right)$.\n",
    "\n",
    "- **Relaxation Factor ($\\omega$)**: A parameter in SOR method; $\\omega=1$ gives Gauss-Seidel, $0 < \\omega < 1$ under-relaxes, $1 < \\omega < 2$ over-relaxes for potentially faster convergence.\n",
    "\n",
    "- **Convergence**: The process by which an iterative method approaches the exact solution within a specified tolerance.\n",
    "\n",
    "- **Tolerance ($\\epsilon$)**: The acceptable error threshold for stopping an iterative method (e.g., when $\\|x_{\\text{new}} - x_{\\text{old}}\\| < \\epsilon$).\n",
    "\n",
    "- **Iteration**: A single step in an iterative algorithm that refines the solution approximation.\n",
    "\n",
    "- **Forward Substitution**: A method to solve lower triangular systems $L y = b$ by solving for $y$ sequentially from top to bottom.\n",
    "\n",
    "- **Backward Substitution**: A method to solve upper triangular systems $U x = y$ by solving for $x$ sequentially from bottom to top.\n",
    "\n",
    "- **Pivoting**: Row/column exchanges in LU decomposition to improve numerical stability by avoiding division by small numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae161b4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731de1c7",
   "metadata": {},
   "source": [
    "# Vector and Matrix Norms and Condition Numbers\n",
    "\n",
    "This notebook provides an introduction to vector norms, matrix norms, and condition numbers, which are fundamental concepts in numerical linear algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729233a",
   "metadata": {},
   "source": [
    "## Vector Norms\n",
    "\n",
    "A vector norm is a function that assigns a non-negative length or size to a vector. Common vector norms include:\n",
    "\n",
    "- **L1 norm (Manhattan norm)**: $\\|x\\|_1 = \\sum_{i=1}^n |x_i|$\n",
    "- **L2 norm (Euclidean norm)**: $\\|x\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}$\n",
    "- **L∞ norm (Maximum norm)**: $\\|x\\|_\\infty = \\max_{i=1}^n |x_i|$\n",
    "\n",
    "These norms satisfy the properties of:\n",
    "1. Positive definiteness: $\\|x\\| \\geq 0$ and $\\|x\\| = 0$ iff $x = 0$\n",
    "2. Homogeneity: $\\|cx\\| = |c| \\|x\\|$\n",
    "3. Triangle inequality: $\\|x + y\\| \\leq \\|x\\| + \\|y\\|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c02a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm of [ 3  4 -5]: 12.0\n",
      "L2 norm of [ 3  4 -5]: 7.0710678118654755\n",
      "L∞ norm of [ 3  4 -5]: 5.0\n",
      "Manual L1: 12\n",
      "Manual L2: 7.0710678118654755\n",
      "Manual L∞: 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example vector\n",
    "x = np.array([3, 4, -5])\n",
    "\n",
    "# L1 norm\n",
    "l1_norm = np.linalg.norm(x, 1)\n",
    "print(f\"L1 norm of {x}: {l1_norm}\")\n",
    "\n",
    "# L2 norm\n",
    "l2_norm = np.linalg.norm(x, 2)\n",
    "print(f\"L2 norm of {x}: {l2_norm}\")\n",
    "\n",
    "# L-infinity norm\n",
    "linf_norm = np.linalg.norm(x, np.inf)\n",
    "print(f\"L∞ norm of {x}: {linf_norm}\")\n",
    "\n",
    "# Manual calculation for verification\n",
    "print(f\"Manual L1: {np.sum(np.abs(x))}\")\n",
    "print(f\"Manual L2: {np.sqrt(np.sum(x**2))}\")\n",
    "print(f\"Manual L∞: {np.max(np.abs(x))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ef6a9",
   "metadata": {},
   "source": [
    "## Matrix Norms\n",
    "\n",
    "Matrix norms extend the concept of vector norms to matrices. Common matrix norms include:\n",
    "\n",
    "- **Induced norms**: Based on vector norms\n",
    "  - 1-norm: $\\|A\\|_1 = \\max_j \\sum_i |a_{ij}|$ (maximum column sum)\n",
    "  - 2-norm: $\\|A\\|_2 = \\sigma_1$ (largest singular value)\n",
    "  - ∞-norm: $\\|A\\|_\\infty = \\max_i \\sum_j |a_{ij}|$ (maximum row sum)\n",
    "\n",
    "- **Frobenius norm**: $\\|A\\|_F = \\sqrt{\\sum_{i,j} a_{ij}^2}$ (square root of sum of squares)\n",
    "\n",
    "Note: The Frobenius norm is not an induced (operator) norm; it is unitarily invariant and submultiplicative.\n",
    "\n",
    "Matrix norms satisfy similar properties to vector norms and are submultiplicative: $\\|AB\\| \\leq \\|A\\| \\|B\\|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7d98612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [-1  0  2]]\n",
      "\n",
      "1-norm: 11.0\n",
      "2-norm: 9.560659131630937\n",
      "∞-norm: 15.0\n",
      "Frobenius norm: 9.797958971132712\n",
      "Manual 1-norm (max column sum): 11\n",
      "Manual ∞-norm (max row sum): 15\n"
     ]
    }
   ],
   "source": [
    "# Example matrix\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [-1, 0, 2]])\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "# Matrix norms\n",
    "norm_1 = np.linalg.norm(A, 1)\n",
    "norm_2 = np.linalg.norm(A, 2)\n",
    "norm_inf = np.linalg.norm(A, np.inf)\n",
    "norm_fro = np.linalg.norm(A, 'fro')\n",
    "\n",
    "print(f\"1-norm: {norm_1}\")\n",
    "print(f\"2-norm: {norm_2}\")\n",
    "print(f\"∞-norm: {norm_inf}\")\n",
    "print(f\"Frobenius norm: {norm_fro}\")\n",
    "\n",
    "# Manual verification for 1-norm (max column sum)\n",
    "col_sums = np.sum(np.abs(A), axis=0)\n",
    "print(f\"Manual 1-norm (max column sum): {np.max(col_sums)}\")\n",
    "\n",
    "# Manual verification for ∞-norm (max row sum)\n",
    "row_sums = np.sum(np.abs(A), axis=1)\n",
    "print(f\"Manual ∞-norm (max row sum): {np.max(row_sums)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb22f19",
   "metadata": {},
   "source": [
    "## Applications and When to Use Different Norms\n",
    "\n",
    "### Vector Norms\n",
    "\n",
    "**L1 Norm ($\\ell_1$)**:\n",
    "- **Use when**: You want sparsity or robustness to outliers (in regression contexts)\n",
    "- **Applications**: Compressed sensing, LASSO regression, signal processing where you want to promote sparse solutions\n",
    "- **Advantages**: Promotes sparsity when used as a regularizer (e.g., LASSO); often more robust to outliers than L2 in regression settings\n",
    "- **Example**: In machine learning, L1 regularization encourages feature selection\n",
    "\n",
    "**L2 Norm ($\\ell_2$)**:\n",
    "- **Use when**: You want physical interpretations or smooth solutions\n",
    "- **Applications**: Least squares problems, physics (energy, distance), Gaussian processes\n",
    "- **Advantages**: Differentiable everywhere, corresponds to Euclidean distance\n",
    "- **Example**: Standard distance measurement, error minimization in regression\n",
    "\n",
    "**L∞ Norm ($\\ell_\\infty$)**:\n",
    "- **Use when**: You care about the worst-case scenario or maximum deviation\n",
    "- **Applications**: Control theory, stability analysis, approximation theory\n",
    "- **Advantages**: Measures the largest component, useful for bounds\n",
    "- **Example**: In numerical analysis, checking convergence by maximum error\n",
    "\n",
    "### Matrix Norms\n",
    "\n",
    "**Induced Norms**:\n",
    "- **1-norm**: Useful when you want to bound the maximum column effect\n",
    "- **∞-norm**: Useful when you want to bound the maximum row effect\n",
    "- **2-norm**: Most commonly used, relates to singular values and stability\n",
    "\n",
    "**Frobenius Norm**:\n",
    "- **Use when**: You want a measure similar to the L2 vector norm for matrices\n",
    "- **Applications**: Matrix approximation, low-rank approximations, total energy\n",
    "- **Advantages**: Easy to compute, relates to the sum of squared elements\n",
    "\n",
    "### Choosing Norms in Practice\n",
    "\n",
    "- **For error analysis**: Use the norm that matches your error tolerance criteria\n",
    "- **For algorithm stability**: Use 2-norm for spectral properties\n",
    "- **For sparse solutions**: Use L1 norm (as a regularizer)\n",
    "- **For worst-case bounds**: Use L∞ norm\n",
    "- **For computational efficiency**: Choose norms that are easy to compute for your problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caea886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector 1: [1 2 3 4 5]\n",
      "Vector 2: [  1   2   3   4 100]\n",
      "\n",
      "Vector 1:\n",
      "  L1 norm: 15.00\n",
      "  L2 norm: 7.42\n",
      "  L∞ norm: 5.00\n",
      "\n",
      "Vector 2:\n",
      "  L1 norm: 110.00\n",
      "  L2 norm: 100.15\n",
      "  L∞ norm: 100.00\n",
      "\n",
      "Notice how:\n",
      "- L1 norm is most affected by the outlier (sum-based, so large values dominate the total)\n",
      "- L2 norm is also strongly affected (due to squaring large values)\n",
      "- L∞ norm is directly the maximum component (equals the outlier)\n",
      "\n",
      "Matrix norm applications:\n",
      "Matrix A (well-conditioned):\n",
      "[[1.   0.01]\n",
      " [0.01 1.  ]]\n",
      "2-norm condition number: 1.02\n",
      "\n",
      "Matrix B (ill-conditioned):\n",
      "[[1.    0.   ]\n",
      " [0.    0.001]]\n",
      "2-norm condition number: 1000.00\n",
      "\n",
      "The 2-norm condition number helps identify matrices that amplify errors in solutions.\n"
     ]
    }
   ],
   "source": [
    "# Practical example: Different norms give different results\n",
    "import numpy as np\n",
    "\n",
    "# Example vectors with outliers\n",
    "v1 = np.array([1, 2, 3, 4, 5])  # No outliers\n",
    "v2 = np.array([1, 2, 3, 4, 100])  # One large outlier\n",
    "\n",
    "print(\"Vector 1:\", v1)\n",
    "print(\"Vector 2:\", v2)\n",
    "print()\n",
    "\n",
    "# Compare norms\n",
    "for vec, name in [(v1, \"Vector 1\"), (v2, \"Vector 2\")]:\n",
    "    l1 = np.linalg.norm(vec, 1)\n",
    "    l2 = np.linalg.norm(vec, 2)\n",
    "    l_inf = np.linalg.norm(vec, np.inf)\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  L1 norm: {l1:.2f}\")\n",
    "    print(f\"  L2 norm: {l2:.2f}\")\n",
    "    print(f\"  L∞ norm: {l_inf:.2f}\")\n",
    "    print()\n",
    "\n",
    "print(\"Notice how:\")\n",
    "print(\"- L1 norm is most affected by the outlier (sum-based, so large values dominate the total)\")\n",
    "print(\"- L2 norm is also strongly affected (due to squaring large values)\")\n",
    "print(\"- L∞ norm is directly the maximum component (equals the outlier)\")\n",
    "print()\n",
    "\n",
    "# Matrix norm example\n",
    "print(\"Matrix norm applications:\")\n",
    "A = np.array([[1, 0.01], [0.01, 1]])\n",
    "B = np.array([[1, 0], [0, 0.001]])  # Ill-conditioned\n",
    "\n",
    "print(\"Matrix A (well-conditioned):\")\n",
    "print(A)\n",
    "print(f\"2-norm condition number: {np.linalg.cond(A):.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"Matrix B (ill-conditioned):\")\n",
    "print(B)\n",
    "print(f\"2-norm condition number: {np.linalg.cond(B):.2f}\")\n",
    "print()\n",
    "\n",
    "print(\"The 2-norm condition number helps identify matrices that amplify errors in solutions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861d8e27",
   "metadata": {},
   "source": [
    "## Condition Numbers\n",
    "\n",
    "The condition number of an invertible matrix A with respect to a norm is defined as:\n",
    "\n",
    "$\\kappa(A) = \\|A\\| \\, \\|A^{-1}\\|$\n",
    "\n",
    "It measures how sensitive the solution of $Ax = b$ is to perturbations in A and b.\n",
    "\n",
    "- **Well-conditioned**: $\\kappa(A) \\approx 1$\n",
    "- **Ill-conditioned**: $\\kappa(A) \\gg 1$\n",
    "\n",
    "For the 2-norm, $\\kappa_2(A) = \\frac{\\sigma_1}{\\sigma_n}$ (ratio of largest to smallest singular value). The condition number depends on the chosen norm (by default, many libraries including `np.linalg.cond` use the 2-norm unless otherwise specified).\n",
    "\n",
    "In many models, the relative error in the solution can be bounded by roughly the condition number times the relative error in the input data (bounds depend on the precise perturbation model and norm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f2cba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Condition number of identity matrix: 1.0\n",
      "\n",
      "Condition number of matrix B: 1.2222222222222225\n",
      "Matrix B:\n",
      "[[1.  0.1]\n",
      " [0.1 1. ]]\n",
      "\n",
      "Condition number of Hilbert matrix: 524.0567775860644\n",
      "Hilbert matrix:\n",
      "[[1.         0.5        0.33333333]\n",
      " [0.5        0.33333333 0.25      ]\n",
      " [0.33333333 0.25       0.2       ]]\n",
      "\n",
      "Exact solution: [1 1 1]\n",
      "Right-hand side b: [1.83333333 1.08333333 0.78333333]\n",
      "Perturbed solution: [1.009 0.964 1.03 ]\n",
      "Relative error in solution: 0.027549954627900785\n",
      "Relative error in RHS: 0.00044072396956813445\n",
      "Amplification factor: 62.51067908763164\n"
     ]
    }
   ],
   "source": [
    "# Condition number examples\n",
    "\n",
    "# Well-conditioned matrix (identity)\n",
    "I = np.eye(3)\n",
    "cond_I = np.linalg.cond(I)\n",
    "print(f\"Condition number of identity matrix: {cond_I}\")\n",
    "print()\n",
    "\n",
    "# Moderately conditioned matrix\n",
    "B = np.array([[1, 0.1],\n",
    "              [0.1, 1]])\n",
    "cond_B = np.linalg.cond(B)\n",
    "print(f\"Condition number of matrix B: {cond_B}\")\n",
    "print(\"Matrix B:\")\n",
    "print(B)\n",
    "print()\n",
    "\n",
    "# Ill-conditioned matrix (Hilbert matrix)\n",
    "H = np.array([[1, 1/2, 1/3],\n",
    "              [1/2, 1/3, 1/4],\n",
    "              [1/3, 1/4, 1/5]])\n",
    "cond_H = np.linalg.cond(H)\n",
    "print(f\"Condition number of Hilbert matrix: {cond_H}\")\n",
    "print(\"Hilbert matrix:\")\n",
    "print(H)\n",
    "print()\n",
    "\n",
    "# Demonstrate sensitivity to perturbations\n",
    "x_exact = np.array([1, 1, 1])\n",
    "b = H @ x_exact\n",
    "print(f\"Exact solution: {x_exact}\")\n",
    "print(f\"Right-hand side b: {b}\")\n",
    "\n",
    "# Add small perturbation to b\n",
    "delta_b = np.array([0.001, 0, 0])\n",
    "b_pert = b + delta_b\n",
    "\n",
    "# Solve perturbed system\n",
    "x_pert = np.linalg.solve(H, b_pert)\n",
    "print(f\"Perturbed solution: {x_pert}\")\n",
    "print(f\"Relative error in solution: {np.linalg.norm(x_pert - x_exact) / np.linalg.norm(x_exact)}\")\n",
    "print(f\"Relative error in RHS: {np.linalg.norm(delta_b) / np.linalg.norm(b)}\")\n",
    "print(f\"Amplification factor: {np.linalg.norm(x_pert - x_exact) / np.linalg.norm(x_exact) / (np.linalg.norm(delta_b) / np.linalg.norm(b))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de2055d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- **Vector norms** measure the \"size\" of vectors with different properties\n",
    "- **Matrix norms** extend this concept to matrices and are crucial for analyzing linear transformations\n",
    "- **Condition numbers** quantify how errors in the input propagate to errors in the output of linear systems\n",
    "- **Applications** guide when to choose different norms based on your specific problem requirements\n",
    "\n",
    "Understanding these concepts is essential for:\n",
    "- Analyzing the stability of numerical algorithms\n",
    "- Choosing appropriate solution methods for linear systems\n",
    "- Interpreting the accuracy of computed solutions\n",
    "- Selecting norms that match your error criteria or computational goals\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
